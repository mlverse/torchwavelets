#######################################################################################
#
# Time-domain calculation and wavelet implementations ported and refactored from:
# https://github.com/QUVA-Lab/PyTorchWavelets/blob/master/wavelets_pytorch/transform.py
# https://github.com/QUVA-Lab/PyTorchWavelets/blob/master/wavelets_pytorch/network.py
# Comments/documentation ported/adapted correspondingly.
#
# COI calculation ported from https://github.com/aaren/wavelets/blob/master/wavelets/transform.py#L550.
#
# The default method does not use neural-network convolution, but the FFT, so it can
# performantly be run for large time series even when no GPU is available.
#
#######################################################################################

#' Continuous wavelet transform as described in Torrence and Compo,
#' "A Practical Guide to Wavelet Analysis".
#'
#' @details There is a time-domain as well as a Fourier-domain implementation.
#' Like _QUVA-Lab/PyTorchWavelets_, the time-domain method uses a filter bank
#' consisting of `torch::nn_conv1d()` modules. This implementation will work with
#' batches of signals. The alternative, spectral-domain multiplication followed by
#' the inverse Fourier transform, is the default. For long signals, and when no
#' GPU is available, this is the recommended way.
#' Both implementations expect input sequences to be one-dimensional.
#'
#' @importFrom torch nn_module
#' @importFrom torch torch_stack
#' @importFrom torch torch_is_complex
#' @importFrom torch nn_module
#' @importFrom torch torch_tensor
#' @importFrom torch torch_cat
#' @importFrom torch torch_reciprocal
#' @importFrom torch nn_conv1d
#' @importFrom torch torch_arange
#' @importFrom torch torch_abs
#' @importFrom torch torch_hstack
#' @importFrom torch torch_where
#' @importFrom torch torch_long
#' @importFrom torch torch_fft_fft
#' @importFrom torch torch_fft_fftfreq
#' @importFrom torch torch_fft_ifft
#' @importFrom torch cuda_is_available
#'
#' @export

WaveletTransform <- R6::R6Class(

  "WaveletTransform",
  lock_objects = FALSE,
  public = list(
    #' @field filters the filters used in the time-domain implementation
    filters = NULL,
    #' @field is_complex_wavelet whether the wavelet has complex values
    is_complex_wavelet = NULL,
    #' @field convs the `nn_conv1d()` modules used in the time-domain implementation
    convs = NULL,
    #' @description initialize the main object, and possibly pre-compute required fields.
    #' @param signal_length length of the signal to be processed
    #' @param dt sample spacing, default is 1
    #' @param dj scale distribution parameter, default is 0.125
    #' @param wavelet wavelet object
    #' @param fourier whether to run in the frequency domain
    initialize = function(signal_length, dt = 1, dj = 0.125, wavelet = torchwavelets::Morlet$new(), fourier = TRUE) {
      self$signal_length <- signal_length
      self$dt <- dt
      self$dj <- dj
      self$wavelet <- wavelet
      self$fourier <- fourier
      self$scale_minimum <- self$compute_minimum_scale()
      self$scales <- self$compute_optimal_scales()
      self$is_complex_wavelet <- wavelet$is_complex

      if (!fourier) {
        self$filters <- self$build_filters()
        self$convs <- self$filter_bank(self$filters)
      }
    },
    #' @description Determines the optimal scale distribution (see Torrence & Compo, Eq. 9-10), and then initializes
    #' the filter bank consisting of re-scaled versions of the mother wavelet. Also includes normalization.
    build_filters = function() {
      filters <- list()
      for (i in 1:length(self$scales)) {
        # Number of points needed to capture wavelet
        M <- 10 * self$scales[i] / self$dt
        # Times to use, centered at zero
        t <- torch_arange((-M + 1) / 2, (M + 1) / 2) * self$dt
        if (length(t) %% 2 == 0) {
          t <- t[1:-2] # requires odd filter size
        }
        # Sample wavelet and normalize
        norm <- (self$dt / self$scales[i])^.5
        filters[[i]] <- norm * self$wavelet$time(t, s = self$scales[i])
      }
      filters
    },
    #' @description Given a list of temporal 1D filters of variable size, this method
    #' creates a list of `nn_conv1d()` objects that collectively form the filter bank.
    #' @param filters the filters generated by `build_filters()`
    #' @param padding_type the type of padding to use with `nn_conv1d()`
    filter_bank = function(filters, padding_type = "same") {
      filter_bank <- list()
      chn_out <- if (self$is_complex_wavelet) 2 else 1
      for (i in 1:length(filters)) {
        filt_weights <- if (self$is_complex_wavelet) torch_cat(list(filters[[i]]$real$unsqueeze(1), filters[[i]]$imag$unsqueeze(1)), dim = 1) else filters[[i]]$unsqueeze(1)
        filt_weights <- filt_weights$unsqueeze(2) # append chn_in dimension
        filt_size <- dim(filt_weights)[3] # filter length
        padding <- self$get_padding(padding_type, filt_size)
        conv <- nn_conv1d(1, chn_out, kernel_size = filt_size, padding = padding, bias = FALSE)
        conv$weight$requires_grad_(FALSE)
        if (cuda_is_available()) conv <- conv$cuda()
        conv$weight[ , , ] <- filt_weights
        filter_bank[[i]] <- conv
      }
      filter_bank
    },
    #' @description Takes a batch of signals and convolves each signal with all elements
    #' in the filter bank. After convolving the entire filter bank, the method returns
    #' a tensor of shape `[batch_size,n_scales,1 or 2,T]` (the next-to-last dimension
    #' being of size 1 for real wavelets, 2 for complex ones; and T being the transformed values).
    #' @param x the input signal
    cwt_time = function(x) {
      # Takes a batch of signals and convolves each signal with all elements
      # in the filter bank. After convolving the entire filter bank, the method returns
      # a tensor of shape `[batch_size,n_scales,1 or 2,T]` (the next-to-last dimension
      # being of size 1 for real wavelets, 2 for complex ones; and T being the transformed values).
      if (is.null(self$filters)) stop("To compute the transform in the time domain, need to instantiate WaveletTransform passing fourier = FALSE")
      results <- list()
      if (cuda_is_available()) x <- x$cuda()
      for (i in 1:length(self$convs)) {
        results[[i]] <- self$convs[[i]](x)
      }
      results <- torch_stack(results) # [n_scales,batch_size,2,t]
      results <- results$permute(c(2, 1, 3, 4)) # [batch_size,n_scales,2,t]
      results <- results$detach()
      results$cpu()
    },
    #' @description Takes a single signal and computes the wavelet transform in the Fourier domain.
    #' The returned value has shape `[n_scales, T]`, where T (the transformed values)
    #' can be a complex tensor.
    #' @param x the input signal
    cwt_freq = function(x) {
      fft_signal <- torch_fft_fft(x)
      fftfreqs <- torch_fft_fftfreq(length(fft_signal), d = self$dt) * 2 * pi
      norm <- (2 * pi * self$scales / self$dt) ^ .5
      wavelet_fourier <- norm$unsqueeze(2) * self$wavelet$frequency(fftfreqs, self$scales$unsqueeze(2))
      out <- torch_fft_ifft(fft_signal$unsqueeze(1) * wavelet_fourier$conj())
      out
    },
    #' @description computes the wavelet transform, either in time or in frequency,
    #' depending on whether `self$fourier` is true or false.
    #' @param x the input signal
    cwt = function(x) {
      if (!self$fourier) {
        num_examples <- x$ndim
        if (num_examples == 1) {
          # Prepend batch and chn_in dimensions
          # [signal_length] => [batch_size,1,signal_length]
          x <- x$unsqueeze(1)$unsqueeze(1)
        } else if (x$ndim == 2) {
          # Just insert chn_in dimension
          # [batch_size,signal_length] => [batch_size,1,signal_length]
          x <- x$view(c(dim(x)[1], 1, dim(x)[2]))
        }
        cwt <- self$cwt_time(x)
        if (self$is_complex_wavelet) {
          # Combine real and imag parts. Returns object of shape
          # [batch_size,n_scales,signal_length] of type `torch_complex()`
          cwt <- cwt[, , 1, ] * torch_complex(1, 0) + cwt[, , 2, ] * torch_complex(0, 1)
        } else {
          # Remove the chn_out dimension to obtain an object of shape [batch_size,n_scales,signal_length].
          cwt <- cwt$squeeze(3)
        }
        # Remove batch dimension if single example
        if (num_examples == 1) {
          cwt <- cwt$squeeze(1)
        }
      } else {
        cwt <- self$cwt_freq(x)
        if (!self$is_complex_wavelet) {
          cwt <- cwt$real
        }
      }
      cwt
    },
    #' @description Determines the optimal scale distribution (see Torrence & Compo, Eq. 9-10).
    compute_optimal_scales = function() {
      J <- floor((1 / self$dj) * log2(self$signal_length * self$dt / self$scale_minimum))
      scales <- self$scale_minimum * 2^(self$dj * torch_arange(0, J))
      scales
    },
    #' @description Performs CWT and converts to a power spectrum (scalogram). See Torrence & Compo, Section 4d.
    # Expects a batch of input signals of shape `[batch_size,signal_length]` and
    # returns a scalogram for each signal `[batch_size,n_scales,signal_length]`
    #' @param x the input signal
    #' @param unbias whether to unbias the power spectrum, as in Liu et al. 2007.
    power = function(x, unbias = FALSE) {
      if (unbias) (torch_abs((self$cwt(x))$T)^2 / self$scales)$T else torch_abs(self$cwt(x))^2
    },
    #' @description compute number of padding values desired
    #' @param padding_type the padding type to use
    #' @param kernel_size the kernel size
    get_padding = function(padding_type, kernel_size) {
      if (padding_type == "same") floor((kernel_size - 1) / 2) else 0
    },
    #' @description Choose s0 so that the equivalent Fourier period is 2 * dt. See Torrence & Compo Sections 3f and 3h.
    compute_minimum_scale = function() {
      dt <- self$dt
      f <- self$wavelet$fourier_period
      func_to_solve <- function(s) {
        f(s) - 2 * dt
      }
      uniroot(func_to_solve, c(0, 10))$root
    },
    #' @description equivalent Fourier period
    #' @param s scaling factor
    fourier_period = function(s) {
      self$wavelet$fourier_period(s)
    },
    #' @description compute the scale from the fourier period
    #' @param p Fourier period
    scale_from_period = function(p) {
      self$wavelet$scale_from_period(p)
    },
    #' @description Fourier period corresponding to scales
    fourier_periods = function() {
      self$fourier_period(self$scales)
    },
    #' @description Fourier period corresponding to scales
    fourier_frequencies = function() {
      torch_reciprocal(self$fourier_periods())
    },
    #' @description returns a pair of tensors that describes the cone of influence as a curve of time and scales
    #' @param t_min the smallest time value in the signal
    #' @param t_max the largest time value in the signal
    coi = function(t_min, t_max) {
      w_coi <- self$wavelet$coi(self$scales)
      t_mid <- t_min + (t_max - t_min) / 2

      c_1 <- t_min + w_coi
      c_2 <- t_max - w_coi
      C <- torch_hstack(list(
        c_1[(torch_where(c_1 < t_mid)[[1]])$to(dtype = torch_long())],
        c_2[(torch_where(c_2 > t_mid)[[1]])$to(dtype = torch_long())]
      ))
      S <- torch_hstack(list(
        self$scales[(torch_where(c_1 < t_mid)[[1]])$to(dtype = torch_long())],
        self$scales[(torch_where(c_2 > t_mid)[[1]])$to(dtype = torch_long())]
      ))

      iC <- C$to(dtype = torch_long())$argsort()
      sC <- C[iC]
      sS <- S[iC]
      list(sC, sS)
    }
  )
)

#' Wrapper constructor for the continuous wavelet transform as described in Torrence and Compo,
#' "A Practical Guide to Wavelet Analysis".
#'
#' @seealso WaveletTransform
#'
#' @param signal_length length of the signal to be processed
#' @param dt sample spacing, default is 1
#' @param dj scale distribution parameter, default is 0.125
#' @param wavelet wavelet object
#' @param fourier whether to run in the frequency domain
#'
#'
#' @export
wavelet_transform <- function(signal_length, dt = 1, dj = 0.125,
                              wavelet = torchwavelets::Morlet$new(), fourier = TRUE) {
  WaveletTransform$new(signal_length, dt, dj, wavelet, fourier)
}
